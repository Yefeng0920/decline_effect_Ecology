---
title: "The use of multilevel multi-moderator meta-regression to detect two forms of publication bias: decline effect and small-study effect"
subtitle: "Tutorial on testing publication bias"
author: "Yefeng Yang, Malgorzata Lagisz, Shinichi Nakagawa"
output:
  rmdformats::robobook:
    code_folding: show
    self_contained: true
    thumbnails: false
    lightbox: true
pkgdown:
  as_is: true   
bibliography: "REFERENCES.bib"
csl: "Ecology.csl"
link-citations: yes
---

# Preface

This tutorial is a supplementary material of our Comment on @costello2022decline:

> Yefeng Yang, Malgorzata Lagisz, Shinichi Nakagawa, 2022. Decline effects are rare in ecology: Comment. EcoEvoRxiv.

The aim of this tutorial is to  educate ecological meta-analysts how to properly conduct and report two common forms of publication bias: decline effect and small-study effect. 

# Loading packages

Load the necessary `R` packages for this tutorial on publication bias test. The main `R` packages used in this tutorial are `metafor` (for model fitting; @viechtbauer2010conducting) and `orchaRd` (for results reporting; @nakagawa2021orchard). All other `R` packages are used for data manipulations, visualizations and rmarkdown knitting. 

```{r, cache = FALSE}
pacman::p_load(tidyverse, 
               knitr,
               DT,
               readxl, 
               metafor,
               orchaRd, # install the latest version via devtools::install_github("daniel1noble/orchaRd", force = TRUE, build_vignettes = TRUE)
               patchwork,
               ggplot2,
               pander,
               formatR,
               rmdformats
               )
```

As we elaborated in the main text and elsewhere (@nakagawa2022methods), a straightforward way to identify decline effect is to regress effect size estimates on the publication year. But to do it properly, we need to account for the heterogeneity and non-independence among the effect size estimates. This a so-called **multilevel multi-moderator meta-regression**. Mathematically, this method can be expressed as : 

$$
y_{ij} = \beta_{0} + \beta_{year}c(year_{ij}) + \beta_{se}se_{ij} + \sum \beta_{k}x_{ik} + \mu_{(b)j} + \mu_{(w)ij} + e_{ij}, \\ \mu_{(b)j} \sim N(0,\sigma_{(b)}^2)\\ \mu_{(w)ij} \sim N(0,\sigma_{(w)}^2)\\ e_{ij} \sim N(0,\nu_{ij})
$$
The model slopes ($\beta_{year}$) and ($\beta_{se}$) can be used to indicate the presence of decline effect and small-study effect, respectively (@nakagawa2012methodological, @koricheva2019temporal). When the significance test of the model slopes rejects the null hypothesis ($\beta_{year}$ = 0 [no decline effect] or $\beta_{se}$ = 0 [small-study effect]), we will obtain statistically significant $\beta_{year}$ or $\beta_{se}$, which indicate that there is a decline effect or small-study effect. The magnitude of the model slopes can be interpreted as the severity of publication bias. 

There are three points of note: (i) to ease interpretations, it is a good choice to center $year_{ij}$ ($c(year_{ij})$) and other continuous moderator variables, (ii) the inclusion of the fixed-effects terms $\sum \beta_{k}x_{ik}$ is used to maximize the statistical power, and (iii) the two random-effects terms $\mu_{(b)j}$ (between-study effect) and $\mu_{(w)ij}$ (within-study effect) can be used to control for the type I error rates  (@rodgers2021evaluating, @nakagawa2022methods). 

Such a multilevel multi-moderator meta-regression looks complex, but it is not difficult to construct it using existing software, for example, `rma.mv()` function in `metafor` package. Below we randomly choose one meta-analysis paper in @costello2022decline's dataset as an example to show the conduct and reporting of publication bias:

> Montagano L, Leroux S J, Giroux M A, et al. The strength of ecological subsidies across ecosystems: a latitudinal gradient of direct and indirect impacts on food webs[J]. Ecology letters, 2019, 22(2): 265-274.

# Load data from the exampled paper and preprocess

```{r}
# load data
montagano.et.al.2019.ecol.letts.dat <- read.csv(file = "./montagano.et.al.2019.ecol.letts.csv", header = T)

# have a look at the data
head(montagano.et.al.2019.ecol.letts.dat)

# compute effect size and its sampling variance
montagano.et.al.2019.ecol.letts.dat <- escalc(measure = "ROM", 
                                              n1i = n_subsidy, n2i = n_nosubsidy,
                                              m1i = Subsidy_mean, m2i = Nosubsidy_mean, 
                                              sd1i = Subsidy_sd, sd2i = Nosubsidy_sd, 
                                              append=TRUE, replace=TRUE, 
                                              data = montagano.et.al.2019.ecol.letts.dat)

# delete NAs
montagano.et.al.2019.ecol.letts.dat <- montagano.et.al.2019.ecol.letts.dat[!is.na(montagano.et.al.2019.ecol.letts.dat$yi) & !is.na(montagano.et.al.2019.ecol.letts.dat$vi), ]

# have a look at the data
t <- montagano.et.al.2019.ecol.letts.dat %>% DT::datatable()
t
```


# Conduct publication bias test (decline effect and small-study effect)

```{r}
# add an unique identifier to each row (effect size) to account for the residual heterogeneity
montagano.et.al.2019.ecol.letts.dat$obsID <- 1:nrow(montagano.et.al.2019.ecol.letts.dat)
# center publication year and other continuous moderator variables to ease interpretations
## center year
montagano.et.al.2019.ecol.letts.dat$Year.c <- montagano.et.al.2019.ecol.letts.dat$Year - mean(montagano.et.al.2019.ecol.letts.dat$Year)
## center latitude
montagano.et.al.2019.ecol.letts.dat$Latitude.c <- montagano.et.al.2019.ecol.letts.dat$Latitude - mean(montagano.et.al.2019.ecol.letts.dat$Latitude)
## center altitude
montagano.et.al.2019.ecol.letts.dat$Longitude.c <- montagano.et.al.2019.ecol.letts.dat$Longitude - mean(montagano.et.al.2019.ecol.letts.dat$Longitude)

# create a variable to contain sampling error, which can be used as a predictor to identify another important form of publication bias - small-study effect
montagano.et.al.2019.ecol.letts.dat$sei <- sqrt(montagano.et.al.2019.ecol.letts.dat$vi)

# simultaneously detect decline effect and small-study effect 
pub_bias_test <- rma.mv(yi, vi, 
                        random = list(~ 1 | ID, ~ 1 | obsID),
                        mods = ~ Year.c + sei + Latitude.c + Longitude.c + System + Taxon + Taxon -1,
                        test = "t",
                        method = "REML",
                        data = montagano.et.al.2019.ecol.letts.dat) # Latitude,  Longitude,  System, Taxon and Taxon are moderator variables used in the original paper
```

Let's have a look at the model results of the above fitted multilevel multi-moderator meta-regression with:

```{r}
summary(pub_bias_test)
```

# Report the results of the publication bias test

We see that the model slope $\beta_{year}$ (`Year.c`) is not statistically significant at the nominal alpha level (0.05), which indicates that there is no decline effect. But when we visually present the results of the decline effect test (which can be done by `bubble_plot` in `orchaRd`; @nakagawa2021orchard), we can find clearly temporal changes in the effect size magnitude (**Figure 1**). The estimate of slope $\beta_{year}$ is -0.0245 (95% CI = -0.0521 to 0.0031), indicating that the effect size magnitude will decline by 0.245 over 10 years. If we only focus on the dichotomous reports on the decline effect test (*p*-value < 0.05 meaning decline effect *vs.* *p*-value > 0.05 meaning no decline effect), we would neglect the real decline of the effect size magnitude.

```{r decline effect test, fig.cap="Figure 1. Bubble plot showing the relationship between effect size magnitude and publication year"}
de <- bubble_plot(pub_bias_test, mod = "Year.c", 
                  xlab = "Publication year (centered by mean year 2010)", ylab = "Model slope of publication year",
                  group = "ID",
                  data = montagano.et.al.2019.ecol.letts.dat, legend.pos = "none") +
                  theme(axis.text.x = element_text(size = 10, colour = "black"),
                        axis.text.y = element_text(size = 10, colour = "black"),
                        axis.title.x = element_text(size = 10, colour = "black"),
                        plot.title = element_text(size = 10, colour = "black"))
de
```

The similar interpretation philosophy can be applied to the small-study effect. The model slope $\beta_{se}$ (`sei`) is statistically significant at the nominal alpha level (0.05), which indicates that there is a small-study effect. The visual presentation of the model results also confirms that small studies (low precision) are more likely to report large effects (**Figure 2**). The estimate of slope $\beta_{year}$ is very large 0.6292 (95% CI = 0.23 to 1.0283), implying that we should interpret the results and conclusions of @montagano2019strength with cautions. 

```{r small-study effect, fig.cap="Figure 2. Bubble plot showing the relationship between effect size magnitude and sampling error (inverse precision)"}
sse <- bubble_plot(pub_bias_test, mod = "sei", 
                   xlab = "Sampling error", ylab = "Model slope of sampling error",
                   group = "ID",
                   data = montagano.et.al.2019.ecol.letts.dat, legend.pos = "none") +
                   theme(axis.text.x = element_text(size = 10, colour = "black"),
                         axis.text.y = element_text(size = 10, colour = "black"),
                         axis.title.x = element_text(size = 10, colour = "black"),
                         plot.title = element_text(size = 10, colour = "black"))
sse
```


Practitioners can modify the above code to properly identify publication bias (small-study effect and decline effect) and (visually) report the associated results. If you want a `rmd` version, please refer to our [Github repository: Yefeng0920/decline_effect_Ecology](https://github.com/Yefeng0920/decline_effect_Ecology). If you want to have a comprehensive learning of the theoretical knowledge of the publication bias test in ecology and evolution. We recommend you to thoroughly read our recent method paper published in *Methods in Ecology and Evolution* (@nakagawa2022methods), where we summarized the current practice of publication test in ecology and evolution and proposed the multilevel multi-moderator meta-regression method approach.

# References
